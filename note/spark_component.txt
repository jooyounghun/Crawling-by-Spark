아파치 스파크란?
* In memory 기반의 고속 데이터 처리엔진, 기존 하둡(Hadoop)이 MR(Map & Reduce) 작업을 디스크 기반으로 수행하기에 느린 부분을 메모리 기반으로 작업함으로서 성능을 극대화하였다.
* 범용적인 분산 환경의 고성능 클러스터링 플랫폼
* 자바, 파이썬, 스칼라, R 등을 기반으로 구동
* MR(Map & Reduce), 스트리밍 기반의 데이터 처리, 하둡의 하이브(Hive) 처럼 SQL 기반 데이터 처리, 머신 러닝 라이브처리, 유틸리티 등을 제공한다.
하둡의 하이브 = 스파크의 스파크 SQL  비슷하다.

기존의 데이터 분석 방식은
> 데이터 추출(ETL)
> 하둡 Map & Reduce 를 통한 데이터 필터링, 정제
> OLAP 을 통한 리포팅, 통계분석

기본 데이터 분석을 위해서는 여러 플랫폼이 필요했지만 아파치 스파크는 통합해서 지원한다. 단일 시스템에서 배치/스트리밍 처리, SQL/머신러닝, 그래프 프로세싱 등을 지원한다.

데이터 저장 및 활용을 위한 HDFS, 카산드라, HBase, 아마존 S3 등 지원한다.
Apache Spark는 Scala를 기반으로 구현되었지만, 자바, 파이썬 등의 언어를 지원하며 관련 SDK를 포함하고 있다.




----


인프라 계층

* Standalone Scheduler : 스파크가 독립적으로 기동할 수 있다.
* Yarn : 하둡의 종합 플랫폼인 Yarn 위에서도 기동할 수 있다.
* Mesos : Docker 가상화 플랫폼인 Mesos 위에서 기동할 수 있다.


Spark SQL : 구조적 데이터와 반구조적 데이터를 다룰 수 있다. 다양한 데이터 유형의 처리가 가능하다. SQL 을 사용한 쿼리, RDD 와 SQL Table 을 Join 하는 기능을 포함하여 기존 코드와 통합이 가능하다.

Spark Streaming : Real-Time 으로 데이터를 받아 특정 작업을 고성능적으로 처리, 스스로 오류를 발견할 수 있다. RDD 에 제공되는 Operation 과 시간 기반의 Operation 을 제공한다. (시계열 데이터 관련)

SparkML : 머신러닝 라이브러리이다. 머신러닝을 위해 만들어졌고, 분류, 회귀, 클러스터링, 필터링과 같은 일반적인 머신러닝 알고리즘과 함께 특징을 추출, 변형, 차원 감소 및 선택을 위한 도구, ML 파이프라인 구축과 평가, 튜닝을 위한 도구를 제공하며 알고리즘과 모델 및파이프라인의 저장/로드, 데이터 처리, 선형대수학과 통계학 수행을 위한 유틸리티도 포함되어 있다.

GraphX : Scala, Java 그리고 Python 을 위한 High Level API 를 제공하는 DataFrame 에 기반한 Graph 를 제공해주는 Apache Spark 를 위한 패키지.


Reference: https://www.slideshare.net/topcredu/apacje-spark
